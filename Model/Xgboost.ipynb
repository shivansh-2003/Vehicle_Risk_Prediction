{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ugt2KcTj8GwI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv(\"Vehicle Risk Prediction Dataset.csv\")\n",
        "\n",
        "##used in colab since there was issue in xgboost detection in garuda linux\n",
        "\n",
        "# Encode categorical features using LabelEncoder\n",
        "le_visibility = LabelEncoder()\n",
        "le_road_surface_conditions = LabelEncoder()\n",
        "le_weather = LabelEncoder()\n",
        "le_traffic_density = LabelEncoder()\n",
        "le_road_hazards = LabelEncoder()\n",
        "#le_time_of_day = LabelEncoder()\n",
        "le_fatigue_level = LabelEncoder()\n",
        "le_medical_condition = LabelEncoder()\n",
        "le_speeding = LabelEncoder()\n",
        "le_light= LabelEncoder()\n",
        "#le_road_type=LabelEncoder()\n",
        "#le_landscape=LabelEncoder()\n",
        "\n",
        "df['visibility_n'] = le_visibility.fit_transform(df['Visibility'])\n",
        "df['road_surface_conditions_n'] = le_road_surface_conditions.fit_transform(df['Road_Surface_Conditions'])\n",
        "df['weather_n'] = le_weather.fit_transform(df['Weather'])\n",
        "df['traffic_density_n'] = le_traffic_density.fit_transform(df['Traffic_Density'])\n",
        "df['road_hazards_n'] = le_road_hazards.fit_transform(df['Road_Hazards'])\n",
        "#df['time_of_day_n'] = le_time_of_day.fit_transform(df['Time_of_Day'])\n",
        "df['fatigue_level_n'] = le_fatigue_level.fit_transform(df['Fatigue_Level'])\n",
        "df['medical_condition_n'] = le_medical_condition.fit_transform(df['Medical_Condition'])\n",
        "df['speeding_n'] = le_speeding.fit_transform(df['Speeding'])\n",
        "df['light_condition']=le_light.fit_transform(df['Light_Conditions'])\n",
        "#df['roadtype'] = le_road_type.fit_transform(df['Road_Type'])\n",
        "#df['landscape_n']=le_landscape.fit_transform(df['Landscape'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ys9-LPOm9NlS"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['Light_Conditions', 'Road_Type', 'Landscape', 'Visibility', 'Road_Surface_Conditions', 'Weather', 'Traffic_Density', 'Road_Hazards', 'Time_of_Day', 'Fatigue_Level', 'Medical_Condition', 'Speeding','Driver_Age','Last_Service_Months_Ago'], axis='columns')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s9KmOnV09RzW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('Risk_Score', axis=1)\n",
        "y = df['Risk_Score'].apply(lambda x: 1 if x > 50 else 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W45AJMiT9pKs"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KrfpFpB9WWw",
        "outputId": "20bee29d-5ecc-487d-f6c7-883901a4ab4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1168\n",
            "           1       1.00      1.00      1.00      1832\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1168\n",
            "           1       1.00      1.00      1.00      1832\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9993333333333333\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1168\n",
            "           1       1.00      1.00      1.00      1832\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Vehicle Risk Prediction Dataset.csv\")\n",
        "\n",
        "# Encode categorical features using LabelEncoder\n",
        "encoders = {\n",
        "    'Visibility': LabelEncoder(),\n",
        "    'Road_Surface_Conditions': LabelEncoder(),\n",
        "    'Weather': LabelEncoder(),\n",
        "    'Traffic_Density': LabelEncoder(),\n",
        "    'Road_Hazards': LabelEncoder(),\n",
        "    'Fatigue_Level': LabelEncoder(),\n",
        "    'Medical_Condition': LabelEncoder(),\n",
        "    'Speeding': LabelEncoder(),\n",
        "    'Light_Conditions': LabelEncoder(),\n",
        "}\n",
        "\n",
        "for col, le in encoders.items():\n",
        "    df[f'{col}_n'] = le.fit_transform(df[col])\n",
        "\n",
        "# Define features and target\n",
        "X = df[['Visibility_n', 'Road_Surface_Conditions_n', 'Weather_n', 'Traffic_Density_n', 'Road_Hazards_n',\n",
        "        'Fatigue_Level_n', 'Medical_Condition_n', 'Speeding_n', 'Light_Conditions_n']]\n",
        "y = df['Risk_Score'].apply(lambda x: 1 if x > 50 else 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train an XGBoost classifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "\n",
        "# Save model, encoders, and scaler to a single file\n",
        "with open('vehicle_risk_model.pkl', 'wb') as f:\n",
        "    joblib.dump((model, encoders, scaler), f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
